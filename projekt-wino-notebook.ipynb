{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "125d9960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x219f75485d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importowanie bibliotek\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "plt.ioff()  # Wyłączenie trybu interakcyjnego dla matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7381ad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_data(file_path: str, sep: str = \";\") -> pd.DataFrame:\n",
    "    data = pd.read_csv(file_path, sep=sep)\n",
    "    \n",
    "    # Konwersja kolumn do typu float, z wyjątkiem zmiennej celu\n",
    "    for col in data.columns[:-1]:\n",
    "        data[col] = data[col].astype(float)\n",
    "    \n",
    "    # Sprawdzenie i usunięcie brakujących wartości\n",
    "    missing_values = data.isnull().sum()\n",
    "    if missing_values.any():\n",
    "        print(\"Brakujące wartości w kolumnach:\\n\", missing_values)\n",
    "        data = data.dropna()\n",
    "        print(\"Usunięto wiersze z brakującymi wartościami.\\n\")\n",
    "    \n",
    "    print(\"Podstawowe informacje o danych (po czyszczeniu):\")\n",
    "    print(data.info())\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6507702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Funkcja do eksploracyjnej analizy danych ----\n",
    "def visualize_data_distribution(data: pd.DataFrame):\n",
    "    # Histogramy\n",
    "    data.hist(bins=15, layout=(4, 3), figsize=(15, 10))\n",
    "    plt.suptitle(\"Histogramy zmiennych\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Rozkłady zmiennych\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, column in enumerate(data.columns):\n",
    "        plt.subplot(4, 3, i + 1)\n",
    "        sns.kdeplot(data[column], fill=True)\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel(\"Gęstość\")\n",
    "    plt.suptitle(\"Rozkład zmiennych\", fontsize=20)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    # Macierz korelacji\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    sns.heatmap(data.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "    plt.title(\"Macierz korelacji\", fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81890a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Funkcja do macierzy pomyłek ----\n",
    "def plot_confusion_matrix(cm, classes, title):\n",
    "   \n",
    "    plt.figure(figsize=(7, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes, cbar=False)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(\"Przewidziana klasa\")\n",
    "    plt.ylabel(\"Rzeczywista klasa\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b266857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Funkcja do trenowania klasyfikatorów ----\n",
    "def train_classifiers(X_train, X_test, y_train, y_test):\n",
    "   \n",
    "    # Drzewo Decyzyjne\n",
    "    tree_model = DecisionTreeClassifier(random_state=42)\n",
    "    tree_model.fit(X_train, y_train)\n",
    "    y_pred_tree = tree_model.predict(X_test)\n",
    "\n",
    "     # Wizualizacja drzewa decyzyjnego\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plot_tree(tree_model, feature_names=X_train.columns, class_names=[str(i) for i in np.unique(y_train)],\n",
    "              filled=True, fontsize=8, rounded=True)\n",
    "    plt.title(\"Wizualizacja drzewa decyzyjnego\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "    # Raport klasyfikacji dla Drzewa Decyzyjnego\n",
    "    print(\"\\nDrzewo decyzyjne - raport klasyfikacji:\\n\", classification_report(y_test, y_pred_tree, zero_division=0))\n",
    "    cm_tree = confusion_matrix(y_test, y_pred_tree)\n",
    "    plot_confusion_matrix(cm_tree, np.unique(y_test), \"Macierz pomyłek - Drzewo decyzyjne\")\n",
    "  \n",
    "    # Skalowanie danych dla k-NN\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # k-Nearest Neighbors (k-NN)\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn_model.fit(X_train_scaled, y_train)\n",
    "    y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "\n",
    "    # Raport klasyfikacji dla k-NN\n",
    "    print(\"\\nk-NN - raport klasyfikacji:\\n\", classification_report(y_test, y_pred_knn, zero_division=0))\n",
    "    cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "    plot_confusion_matrix(cm_knn, np.unique(y_test), \"Macierz pomyłek - k-NN\")\n",
    "\n",
    "    return tree_model, knn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5debb9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Funkcja do wykresu krzywej uczenia ----\n",
    "def plot_learning_curves(models, X_train, y_train):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for model_name, model in models.items():\n",
    "        train_sizes, train_scores, test_scores = learning_curve(\n",
    "            model, X_train, y_train, cv=5, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 5)\n",
    "        )\n",
    "        plt.plot(train_sizes, np.mean(test_scores, axis=1), label=model_name)\n",
    "    plt.title(\"Krzywe uczenia\", fontsize=16)\n",
    "    plt.xlabel(\"Rozmiar zbioru treningowego\")\n",
    "    plt.ylabel(\"Dokładność\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d13ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Funkcja do regresji ----\n",
    "def train_regressors(X_train, X_test, y_train, y_test):\n",
    "    # Regresja liniowa\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "    y_pred_lin = lin_reg.predict(X_test)\n",
    "    y_pred_lin_rounded = np.round(y_pred_lin)\n",
    "\n",
    "    print(\"\\nRegresja liniowa - RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_lin_rounded)))\n",
    "\n",
    "    # Random Forest\n",
    "    rf_reg = RandomForestRegressor(random_state=42)\n",
    "    rf_reg.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_reg.predict(X_test)\n",
    "    y_pred_rf_rounded = np.round(y_pred_rf)\n",
    "\n",
    "    print(\"Random Forest - RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_rf_rounded)))\n",
    "    \n",
    "    # Wizualizacja\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_pred_lin_rounded, alpha=0.5, label=\"Regresja liniowa\", color=\"blue\")\n",
    "    plt.scatter(y_test, y_pred_rf_rounded, alpha=0.5, label=\"Random Forest\", color=\"red\")\n",
    "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', label=\"Idealna linia\")\n",
    "    plt.xlabel(\"Rzeczywiste wartości\")\n",
    "    plt.ylabel(\"Przewidywane wartości\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Rzeczywiste vs przewidywane wartości\", fontsize=16)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    return lin_reg, rf_reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64b77c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Funkcja do grupowania ----\n",
    "def cluster_data(X, n_clusters=3):\n",
    "    # PCA do redukcji wymiarowości\n",
    "    pca = PCA(n_components=2)\n",
    "    X_reduced = pca.fit_transform(X)\n",
    "\n",
    "    # Grupowanie KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters_kmeans = kmeans.fit_predict(X)\n",
    "\n",
    "    # Grupowanie hierarchiczne\n",
    "    agg_clust = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "    clusters_agg = agg_clust.fit_predict(X)\n",
    "\n",
    "    # Wizualizacja grup\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=clusters_kmeans, cmap=\"viridis\", alpha=0.7)\n",
    "    plt.title(\"K-Means - Grupowanie\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=clusters_agg, cmap=\"viridis\", alpha=0.7)\n",
    "    plt.title(\"Hierarchiczne grupowanie\")\n",
    "    plt.show()\n",
    "    \n",
    "    return clusters_kmeans, clusters_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a640a2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (3400640514.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfile_path = \"C:\\Users\\piotr\\Desktop\\Studja\\Wizualizacja i eksploracja danych biznesowych - C\\Visualisation - Python\\winequality-white.csv\"\u001b[39m\n                                                                                                                                              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "file_path = \"C:/Users/piotr/Desktop/Studja/Wizualizacja i eksploracja danych biznesowych - C/Visualisation - Python/winequality-white.csv\"\n",
    "data = load_and_clean_data(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0123f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Analysis\n",
    "visualize_data_distribution(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6745611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Prepare Split Data\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931881fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_classifiers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train Classifiers\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m tree_model, knn_model = \u001b[43mtrain_classifiers\u001b[49m(X_train, X_test, y_train, y_test)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_classifiers' is not defined"
     ]
    }
   ],
   "source": [
    "# Train Classifiers\n",
    "tree_model, knn_model = train_classifiers(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224af27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Learning Curves\n",
    "plot_learning_curves({\"Drzewo Decyzyjne\": tree_model, \"k-NN\": knn_model}, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61af58a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Regressors\n",
    "lin_reg, rf_reg = train_regressors(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028d56fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "clusters_kmeans, clusters_agg = cluster_data(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
